# WebCrawlerDesign
# 网络爬虫设计
## 准备工作
进去先把需要的库加了：  
一个request库，一个beautifulsoup4库。  
然后建立仨txt文件一个data，一个tasks，一个finishedtasks放在py文件的目录下就可以了。  
tasks里放一条有关sougou百科的词条的链接，比如https://baike.sogou.com/v10763190.htm?fromTitle=github  
如果报错啥pop函数的话就是你爬的链接里没有别的链接，就重新放个超链接多的词条的进去就行了  
## 注意
这个爬虫主要还是来爬搜狗百科的，别的要自己改标签  
